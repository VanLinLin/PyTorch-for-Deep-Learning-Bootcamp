{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08. Milestone PyTorch Paper Replicating \n",
    "\n",
    "The goal of machine learning research paper replicating is: turn a ML research paper into usable code.\n",
    "\n",
    "In this notebook, we're going to be replicating the [Vision Transformer (ViT)](https://arxiv.org/abs/2010.11929) architecture/paper with PyTorch.\n",
    "\n",
    "See ground truth notebook [here](https://www.learnpytorch.io/08_pytorch_paper_replicating/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Get setup\n",
    "\n",
    "Let's import code we're previously written + required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.0.1+cu117', '0.15.2+cu117')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "\n",
    "torch.__version__, torchvision.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from going_modular import data_setup, engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device-agnostic code\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get data\n",
    "\n",
    "The whole goal of what we're trying to do is to replicate the ViT architecture for our FoodVision Mini problem.\n",
    "\n",
    "To do that, we need some data.\n",
    "\n",
    "Namely, the pizza, steat, susui images we've been using so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data\\pizza_steak_sushi directory exists, skipping download.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('data/pizza_steak_sushi')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helper_functions import download_data\n",
    "\n",
    "image_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\", destination=\"pizza_steak_sushi\")\n",
    "\n",
    "image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('data/pizza_steak_sushi/train'),\n",
       " WindowsPath('data/pizza_steak_sushi/test'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup directory paths to train and test images\n",
    "train_dir = image_path / 'train'\n",
    "test_dir = image_path / 'test'\n",
    "\n",
    "train_dir, test_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually creaded transform Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)\n",
      "    ToTensor()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from going_modular import data_setup\n",
    "\n",
    "\n",
    "# Create image size\n",
    "IMG_SIZE = 224  # comes from tabel 3 of the ViT paper\n",
    "\n",
    "# Create transforms pipeline\n",
    "manual_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=(IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "print(F\"Manually creaded transform {manual_transforms}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 3, ['pizza', 'steak', 'sushi'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a batch size of 32 (the paper uses 4096 but this may be too big for our smaller hardware... can always scale up later)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir, test_dir=test_dir, transform=manual_transforms,batch_size=BATCH_SIZE)\n",
    "\n",
    "len(train_dataloader), len(test_dataloader), class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
