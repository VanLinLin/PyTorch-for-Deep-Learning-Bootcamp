{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06. PyTorch Transfer Learning\n",
    "\n",
    "What is transfer learning?\n",
    "\n",
    "Transfer learning involves taking the parameters of what one model has learned on another dataset and applying to our own problem.\n",
    "\n",
    "* Pretrained model = foundation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.13.0+cu117', '0.14.0+cu117')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "\n",
    "torch.__version__, torchvision.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device-agnostic code\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul 16 15:22:47 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 536.40                 Driver Version: 536.40       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3080 ...  WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   54C    P8              11W /  95W |    317MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     11852      C   ...rograms\\Python\\Python310\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     22948      C   ...rograms\\Python\\Python310\\python.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get data\n",
    "\n",
    "We need our pizza, steak, sushi data to build a transfer learning model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\pizza_steak_sushi exists, skipping re-creating.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Setup data path\n",
    "data_path = Path('data/')\n",
    "image_path = data_path / 'pizza_steak_sushi'\n",
    "\n",
    "# If the image folder doesn't exist, download it and prepare it\n",
    "if image_path.is_dir():\n",
    "    print(f'{image_path} exists, skipping re-creating.')\n",
    "else:\n",
    "    print(f'{image_path} does not exist, create it')\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Download pizza, steak, sushi data\n",
    "    with open(image_path / 'pizza_steak_sushi.zip', 'wb') as f:\n",
    "        request = requests.get('https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip')\n",
    "        f.write(request.content)\n",
    "\n",
    "    # Unzip pizza, steak, sushi data\n",
    "    with zipfile.ZipFile(data_path / 'pizza_steak_sushi.zip', 'r') as f:\n",
    "        print('Unzipping pizza, steak, sushi data...')\n",
    "        f.extractall(image_path)\n",
    "\n",
    "    # Remove zip file\n",
    "    os.remove(image_path / 'pizza_steak_sushi.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('data/pizza_steak_sushi/train'),\n",
       " WindowsPath('data/pizza_steak_sushi/test'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup directories path\n",
    "train_dir = image_path / 'train'\n",
    "test_dir = image_path / 'test'\n",
    "\n",
    "train_dir, test_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Datasets and DataLoaders\n",
    "\n",
    "Now we're get some data, want to turn it into PyTorch DataLoaders.\n",
    "\n",
    "To do so, we can use `data_setup.py` and the `create_dataloaders()` function we made in 05. PyTorch Going Modular.\n",
    "\n",
    "There's one thing we have to think about when loading: how to **transform** it?\n",
    "\n",
    "And with `torchvision` 0.13+ there's two ways to do this:\n",
    "1. Manually created transforms.\n",
    "   1. You define what transforms you want to your data to go through.\n",
    "2. Automatically created transforms.\n",
    "   1. The transforms for your data are defined by the model you'd like to use.\n",
    "\n",
    "Important point: when using a pretrained model, it's important that the data (including your custom data) that you pass through it is **transformed** in the same way that the data the model was trained on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Creating a transform for `torchvision.models` (manual creation)\n",
    "\n",
    "`torchvision.models` contains pretrained models (models ready for transfer learning ) right within `torchvision`.\n",
    "\n",
    "\n",
    "> All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224.The images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225].You can use the following transform to normalize:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "normalize = transforms.Normalize(mean=[.485, .456, .406],\n",
    "                                 std=[.229, .224, .225])\n",
    "\n",
    "\n",
    "manual_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize])  # make sure images have the same distribution as ImageNet (where our pretrained models have been trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x27fdc025960>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x27fdc027e50>,\n",
       " ['pizza', 'steak', 'sushi'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from going_modular import data_setup\n",
    "\n",
    "\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir, test_dir=test_dir, transform=manual_transforms, batch_size=32)\n",
    "\n",
    "train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
